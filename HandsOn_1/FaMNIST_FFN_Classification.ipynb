{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Neural Network for Classifying Handwritten Digits\n",
    "\n",
    "The data set we will be using is called [MNIST](http://yann.lecun.com/exdb/mnist/). It was create by Yann Lecun and is considered to be the \"hello world\" of datasets for deep learning. \n",
    "\n",
    "MNIST consists of 28x28 pixel images of hand written digis.\n",
    "\n",
    "<center> <img src=\"img/mnist.png\" width=\"300\"/>  </center>\n",
    "\n",
    "<br/>\n",
    "\n",
    "We are going to create a feed forward neural network to classify the digits. This will be a simple network composed of linear layers and activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Transforms\n",
    "\n",
    "When we get the dataset, we will be given tuples that look like:\n",
    "\n",
    "        (PIL image, label)\n",
    "\n",
    "We will need to apply a transform to each image loaded to convert it to a tensor. This can be done using a library included with Pytorch called TorchVision. This library contains datasets, helper functions, transforms, and even whole neural networks that can all be loaded easily.\n",
    "\n",
    "We will use the transform `ToTensor()` which will convert each image to a tensor that we can use in our model. There are lots of other transforms that we have access to such as rotating or flipping images.\n",
    "\n",
    "The `Compose` method is how you string several transforms together. They will be executed in the order they are put in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])  # Try with no normalization for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torchvision has several datasets builtin. These functions make it easy to download and create a dataset from these commonly used datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26427392it [00:05, 4998004.13it/s]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 59557.71it/s]                           \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4423680it [00:02, 1752491.86it/s]                            \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 48963.56it/s]            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=xforms)\n",
    "test_data = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=xforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the datasets are created we use them to instantiate the dataloader. A dataloader is a feature of pytorch that allows you to easily batch and loop over datasets. These can be cusomized by simply writing your own dataset class and feeding it to the dataloader. \n",
    "\n",
    "Dataloaders allow you to control the batch size, number of threads for loading, shuffling, collating and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets take a look at the data\n",
    "\n",
    "Pytorch data loaders are a convenient way to get tensors into your model with very little manual work. Custom datasets are very easy to define if you are using data that doesnt fit well into one of the predefined classes.\n",
    "\n",
    "The dataloaders defined above work just like an iterator. We can get an item from it by calling `next(iter(loader))`. When accessing all of the data we simply have to loop over the dataloader `for data, label in dataloader:`.\n",
    "\n",
    "Lets take a look at how the dataloader returns data to us. For the MNIST dataset (and most imagery data) it returns a tuple where the first element is a  tensor with the shape [batch, channels, height, width], and the second element is the label (in this case an integer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "d = next(iter(train_loader))\n",
    "print(d[0].shape) # the data\n",
    "print(d[1].shape) # the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 5, 1, 8, 7, 4, 5, 9, 7, 4, 1, 3, 6, 1, 5, 0, 9, 7, 5, 9, 8, 7, 6, 3,\n",
       "        8, 0, 5, 6, 5, 4, 1, 1, 6, 7, 9, 7, 1, 3, 2, 2, 9, 8, 3, 5, 7, 4, 7, 2,\n",
       "        1, 6, 8, 1, 1, 2, 4, 2, 0, 1, 3, 0, 3, 3, 7, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1234b6410>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(d[0][0].squeeze().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.layers = torch.nn.Sequential(\n",
    "                            torch.nn.Linear(in_features=784, out_features=128),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(in_features=128, out_features=64),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(in_features=64, out_features=10),\n",
    "                            torch.nn.Softmax(dim=1)\n",
    "                        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    " 1. Why is the input size 784?\n",
    " 2. Why is the output size 10?\n",
    " 3. Why are we using Softmax on the last layer instead of ReLU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Optimizer\n",
    "\n",
    "We will be using the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Loss function\n",
    "\n",
    "For classification problems in general you will use the cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | 6.77 s - loss: 1.7019929071225084\n",
      "Epoch 1 | 7.04 s - loss: 1.6398484457784623\n",
      "Epoch 2 | 7.12 s - loss: 1.6257433548156641\n",
      "Epoch 3 | 7.18 s - loss: 1.61916046915278\n",
      "Epoch 4 | 7.28 s - loss: 1.619771730543962\n",
      "Epoch 5 | 7.37 s - loss: 1.6181215322348101\n",
      "Epoch 6 | 7.38 s - loss: 1.6149971802859926\n",
      "Epoch 7 | 7.48 s - loss: 1.6130223780044362\n",
      "Epoch 8 | 7.47 s - loss: 1.6123608156307927\n",
      "Epoch 9 | 7.49 s - loss: 1.6089249549389901\n",
      "Epoch 10 | 7.53 s - loss: 1.6092814256641657\n",
      "Epoch 11 | 7.62 s - loss: 1.6110854086591238\n",
      "Epoch 12 | 7.53 s - loss: 1.6092799098761097\n",
      "Epoch 13 | 7.54 s - loss: 1.6046220163292468\n",
      "Epoch 14 | 7.51 s - loss: 1.607764533842042\n",
      "Epoch 15 | 7.54 s - loss: 1.610663389854594\n",
      "Epoch 16 | 7.54 s - loss: 1.6081944493088387\n",
      "Epoch 17 | 7.55 s - loss: 1.6087980821951111\n",
      "Epoch 18 | 7.50 s - loss: 1.6084174827726156\n",
      "Epoch 19 | 7.54 s - loss: 1.6060885921724315\n",
      "Epoch 20 | 7.59 s - loss: 1.6023255976786746\n",
      "Epoch 21 | 7.58 s - loss: 1.6007268876155047\n",
      "Epoch 22 | 7.50 s - loss: 1.6075540822960421\n",
      "Epoch 23 | 7.52 s - loss: 1.6042515691409487\n",
      "Epoch 24 | 7.50 s - loss: 1.6078369154858945\n",
      "Epoch 25 | 7.49 s - loss: 1.6065522973725537\n",
      "Epoch 26 | 7.74 s - loss: 1.6022419266100885\n",
      "Epoch 27 | 7.66 s - loss: 1.6051578282801582\n",
      "Epoch 28 | 7.51 s - loss: 1.6058746259858105\n",
      "Epoch 29 | 7.50 s - loss: 1.6066004337786612\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "loss_history = []\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    epoch_time = time.time()\n",
    "    for data, labels in train_loader:\n",
    "        # Flatten the tensors to go from 28x28 -> 784\n",
    "        flat_data = data.view(data.shape[0], -1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(flat_data)\n",
    "        loss = criterion(pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    loss_history.append(epoch_loss/len(train_loader))    \n",
    "    print(f\"Epoch {epoch} | {time.time()-epoch_time:.2f} s - loss: {epoch_loss/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x124bce390>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxV9Z3/8dcny80OIRsgAYnIKqICalG0qFWxWNfiqOO4tL86TtvpMtN22k4dO+2001Znxj7aqkMdt9Zqq6LWDZeqUJUKAdkDiGwhLAkJgZCFLPfz++NeMNBswIWb3PN+Ph555HrOyb2f49F3vvme7/l+zd0REZHElxTvAkRE5PhQ4IuIBIQCX0QkIBT4IiIBocAXEQmIlHgX0JGCggIfPnx4vMsQEekzFi1atNPdC7s6plcG/vDhwyktLY13GSIifYaZberuGHXpiIgEhAJfRCQgFPgiIgGhwBcRCQgFvohIQCjwRUQCQoEvIhIQCRP47s4v/vQhc9dWxbsUEZFeKWEC38yYNW89b62ujHcpIiK9UreBb2YPmVmlma3oZP83zWxJ9GuFmbWZWV5033QzW2Nm68zs27Eu/lD52SGq65uP9ceIiPRJPWnhPwJM72ynu9/t7qe7++nAd4C57l5jZsnAr4DLgHHADWY2LgY1d6ogO43qvfuO5UeIiPRZ3Qa+u88Danr4fjcAT0RfnwWsc/f17t4MPAlceURV9lB+doidCnwRkQ7FrA/fzDKJ/CXwTHTTEKC83SFbots6+/nbzazUzEqrqo7sxmt+dhrVe9WlIyLSkVjetP0M8K679/SvgYO4+yx3n+zukwsLu5zhs1MFWSFqGpppC2thdhGRQ8Uy8K/n4+4cgApgaLt/Lo5uO2bys9Nwh10NauWLiBwqJoFvZv2BTwLPt9u8EBhpZiVmFiLyC+GPsfi8zuRnhwDUrSMi0oFuF0AxsyeAaUCBmW0B7gJSAdz9gehhVwOvuXv9/p9z91Yz+zLwKpAMPOTuK2Nb/sHys9IAoiN1co7lR4mI9DndBr6739CDYx4hMnzz0O0vAy8fSWFHojAn0sKv0kgdEZG/kjBP2kL7Fr66dEREDpVQgd8/I5XkJKO6Xi18EZFDJVTgJyUZeVkhtfBFRDqQUIEPkJ8VYqcCX0TkryRc4Bdkp6lLR0SkAwkY+OrSERHpSMIFfn52miZQExHpQAIGfoiG5jYamlvjXYqISK+ScIFfoLH4IiIdSrjAPzCfjla+EhE5SAIGfvv5dEREZL/EC/wszZgpItKRhAv8gmgLf6fG4ouIHCThAj8jlExWKJmddWrhi4i0l3CBD9G1bdXCFxE5SIIGvp62FRE5VGIGfpaethUROVRCBn5Bdkjj8EVEDpGggZ9GTX0z4bDHuxQRkV4jIQM/PztEW9ipbWyJdykiIr1Ggga+nrYVETlUQgZ+QfRpW618JSLysYQM/AMtfI3FFxE5IEEDX/PpiIgcKiEDf0BmiCRTH76ISHsJGfjJSUZeVoidGosvInJAQgY+RJ+2rVMLX0Rkv8QNfD1tKyJykAQO/DT14YuItJO4gZ+lGTNFRNrrNvDN7CEzqzSzFV0cM83MlpjZSjOb227716PbVpjZE2aWHqvCu1OQHaJuXytNLW3H6yNFRHq1nrTwHwGmd7bTzHKB+4Ar3P0UYGZ0+xDgK8Bkdx8PJAPXH23BPbV/qcMa9eOLiAA9CHx3nwfUdHHIjcBsd98cPb6y3b4UIMPMUoBMYOtR1HpYPp5PR4EvIgKx6cMfBQwws7fNbJGZ3Qzg7hXAPcBmYBuw291f6+xNzOx2Mys1s9KqqqqjLmr/07ZaCEVEJCIWgZ8CTAJmAJcCd5rZKDMbAFwJlAAnAFlmdlNnb+Lus9x9srtPLiwsPOqiCrIiLXwFvohIREoM3mMLUO3u9UC9mc0DTovu2+DuVQBmNhs4B/htDD6zWwfm01EfvogIEJsW/vPAVDNLMbNM4GygjEhXzifMLNPMDLgouv24yAwlk56apLH4IiJR3bbwzewJYBpQYGZbgLuAVAB3f8Ddy8xsDrAMCAMPuvuK6M8+DSwGWoEPgFnH4iQ6qZv8rDTdtBURieo28N39hh4cczdwdwfb7yLyCyIuCnLSNIGaiEhUwj5pC5GVr9SlIyISkdCBn58d0igdEZGoBA/8SB++u8e7FBGRuEvswM8K0Rp29jS2xrsUEZG4S+jA3z+fzk4tZi4iEozA19BMEZEED/wDT9vqxq2ISDACXyN1REQSPPDzMvcHvrp0REQSOvBTkpMYkJlKtW7aiogkduDDx2PxRUSCLvEDX4uZi4gAAQj8yARq6tIREUn8wFcLX0QECEDg52ensbuxhebWcLxLERGJqwAEfmRoZo3mxReRgEv8wNdi5iIiQAACv0CLmYuIAIEI/P0TqKmFLyLBlvCB//EEamrhi0iwJXzgZ6elEEpJ0lh8EQm8hA98M6MgK8TOOrXwRSTYEj7wITqfjlr4IhJwAQl8PW0rIhKMwM9K0ygdEQm8QAR+QU6InfXNuHu8SxERiZtgBH5WGs2tYfbua413KSIicROIwNdYfBGRwAS+5tMREQlG4GdpMXMRkW4D38weMrNKM1vRxTHTzGyJma00s7nttuea2dNmttrMysxsSqwKPxwH5tPRWHwRCbCetPAfAaZ3ttPMcoH7gCvc/RRgZrvdPwfmuPsY4DSg7MhLPXJ5WerDFxHpNvDdfR5Q08UhNwKz3X1z9PhKADPrD5wP/F90e7O71x51xUcglJJE/4xUjcUXkUCLRR/+KGCAmb1tZovM7Obo9hKgCnjYzD4wswfNLKuzNzGz282s1MxKq6qqYlDWwfKzI2PxRUSCKhaBnwJMAmYAlwJ3mtmo6PaJwP3ufgZQD3y7szdx91nuPtndJxcWFsagrIMVZKWxs04tfBEJrlgE/hbgVXevd/edwDwi/fVbgC3u/n70uKeJ/AKIi/zskFa9EpFAi0XgPw9MNbMUM8sEzgbK3H07UG5mo6PHXQSsisHnHZHIBGpq4YtIcKV0d4CZPQFMAwrMbAtwF5AK4O4PuHuZmc0BlgFh4EF33z+E8x+Bx80sBKwHbov9KfRMflYauxpaaG0Lk5IciMcPREQO0m3gu/sNPTjmbuDuDrYvASYfWWmxVZATGYtf09BMUU56nKsRETn+AtPULdBYfBEJuMAE/v75dBT4IhJUAQr8/fPp6MatiARTYAK/IEszZopIsAUm8PtlpJCabBqLLyKBFZjANzOtbSsigRaYwIf9D1+phS8iwRSwwE/TBGoiEliBCvyCLE2vICLBFajAz88OsXPvPtw93qWIiBx3AQv8NJpawjQ0t8W7FBGR4y5QgV+gp21FJMACFfgHnrbVYuYiEkCBCvz9T9uqhS8iQRSowN/fwtdIHREJokAFft7+KZI1Fl9EAihQgZ+emkxOWgpVWsxcRAIoUIEPWsxcRIIrcIFfkK0J1EQkmAIX+JpATUSCKoCBn0a1xuGLSAAFLvALskLU1DfTFtZ8OiISLIEL/PzsNMIOuxrUrSMiwRLAwN//8JUCX0SCJXCB//EEaurHF5FgCWDg759ATS18EQmWwAV+fpZa+CISTIEL/P4ZqSQnmfrwRSRwAhf4SUlGXlZIY/FFJHACF/gA+VkhqurUwheRYOk28M3sITOrNLMVXRwzzcyWmNlKM5t7yL5kM/vAzF6MRcGxUKCnbUUkgHrSwn8EmN7ZTjPLBe4DrnD3U4CZhxzyVaDsSAs8Fgo0n46IBFC3ge/u84CaLg65EZjt7pujx1fu32FmxcAM4MGjrDOm8jVjpogEUCz68EcBA8zsbTNbZGY3t9t3L/AtINzdm5jZ7WZWamalVVVVMSirc0U5adQ3t1FZ13RMP0dEpDeJReCnAJOItOQvBe40s1FmdjlQ6e6LevIm7j7L3Se7++TCwsIYlNW5i8YWAfDcBxXH9HNERHqTWAT+FuBVd693953APOA04FzgCjPbCDwJXGhmv43B5x21k4tymDgsl6dKt+CuWTNFJBhiEfjPA1PNLMXMMoGzgTJ3/467F7v7cOB64E13vykGnxcTMycP5cPKvSwpr413KSIix0VPhmU+AcwHRpvZFjP7vJndYWZ3ALh7GTAHWAYsAB50906HcPYWl08YTHpqEk8t2hLvUkREjouU7g5w9xt6cMzdwN1d7H8bePtwCjvWctJT+fT4wbywZCt3zhhHRig53iWJiBxTgXzSdr+Zk4dSt6+VOSu3xbsUEZFjLtCBf3ZJHsPyMnmqVN06IpL4Ah34SUnGZycV895H1ZTXNMS7HBGRYyrQgQ9w7aRizOBp3bwVkQQX+MAfkpvB1JMLeHrRFsJhjckXkcQV+MCHyM3bitpG3vuoOt6liIgcMwp84JJxA+mXnsJTi8rjXYqIyDGjwAfSU5O58vQhzFmxnd2NLfEuR0TkmFDgR103eSj7WsO8sHRrvEsRETkmFPhR44f0Y8ygHJ4qVbeOiCQmBX6UmTFz8lCWbtnNmu118S5HRCTmFPjtXHX6CaQkmVr5IpKQFPjt5Gen8amxA3n2gwpa2rpdpEtEpE9R4B/iujOLqa5v5s3Vld0fLCLShyjwD3H+yEKKctLUrSMiCUeBf4iU5CSumVjMW2uqtMi5iCQUBX4HZk4upi3sPLtYi5yLSOJQ4HdgRGE2k04cwB9Ky7XIuYgkDAV+J2ZOKuajqno+0CLnIpIgFPidmDFhMBmpybp5KyIJQ4HfiZz0VD596mBeWLqNxua2eJcjInLUFPhdmDm5mL37WjWhmogkBAV+F84uyWNCcX9++OIq1lXujXc5IiJHRYHfBTPj/psmEUpJ4vbHSjVXvoj0aQr8bgzJzeD+myZRvquBrzzxAW1a91ZE+igFfg+cVZLHv18xnrlrq/jpnNXxLkdE5IikxLuAvuLGs4dRtm0Ps+atZ8ygHK6ZWBzvkkREDota+Ifh3z4zjk+clMe3Zy9niR7IEpE+RoF/GFKTk7jvbydRlJPG3/+mlMo9mlxNRPoOBf5hyssK8eAtk6lrauX23yyiqUUPZYlI39Bt4JvZQ2ZWaWYrujhmmpktMbOVZjY3um2omb1lZqui278ay8Ljacygfvz3daezpLyW7z67XBOsiUif0JMW/iPA9M52mlkucB9whbufAsyM7moF/tndxwGfAL5kZuOOrtzeY/r4QXztUyOZvbiC/3tnQ7zLERHpVreB7+7zgJouDrkRmO3um6PHV0a/b3P3xdHXdUAZMOSoK+5FvnLhSC4bP4gfv1zG3LVVPf45/UUgIvEQi2GZo4BUM3sbyAF+7u6PtT/AzIYDZwDvd/YmZnY7cDvAsGHDYlDWsZeUZNwz8zQ27KznH3+3mOe/PJXh+Znsamhha20j23Y3sW13I1trI9+31TaxdXcjlXv2UVKQxcXjBvKpcQOZMKQ/SUkW79MRkQRnPWltRgP7RXcf38G+XwKTgYuADGA+MMPd10b3ZwNzgR+5++yeFDV58mQvLS3t4SnEX3lNA1f+6l2aW8O0hsM0tYQP2p+abAzqn87g/hmc0D+dwpw0llfsZuHGXbSFnaKcND41biAXjx3IlBH5pKcmx+lMRKSvMrNF7j65q2Ni0cLfAlS7ez1Qb2bzgNOAtWaWCjwDPN7TsO+LhuZl8tCtZ/LY/I3kZYYYnBsJ9sG5GZyQm05BVlqHLfhd9c28vbaS11ft4PkPKvjd+5vJDCVz/shCLh43kAvHFDEgK3T8T0hEElIsWvhjgV8ClwIhYAFwPbASeBSocfevHU5Rfa2FHwv7WtuY/1E1r6/awRtlO9ixZx9JBueMKOBb00czoTg33iWKSC/WkxZ+t4FvZk8A04ACYAdwF5AK4O4PRI/5JnAbEAYedPd7zWwq8GdgeXQ7wHfd/eXuCg9i4Lfn7iyv2M3rq3bwxIJyquv3MXNSMd+8dAyFOWnxLk9EeqGYBH48BD3w26trauEXb67j4Xc3kJaSzFcuOplbzykhlKJn5kTkYz0JfKVGL5eTnsp3Pz2WV792PmcOH8CPX17N9Hvn8dbqyniXJiJ9jAK/jzipMJuHbzuLh289E4DbHlnIbQ8vYH2VVuISkZ5R4PcxF4wpYs7Xzue7nx7Dwo27uPTeefzopVXsadJqXCLSNfXh92GVdU3c8+oanlq0hfysELedW8LVZwzhhNyMeJcmIseZbtoGxLIttfzny6uZv74aM5hyUj7XTCzmsvGDyErTGjciQaDAD5hN1fU8+0EFsxdXsLmmgYzUZC4bP4hrJhYzZUQ+yZq+QSRhKfADyt1ZtGkXzyyu4MVlW6lramVQv3SuOmMI10wcwqiBOfEuUURiTIEvNLW08aeySmYv3sLba6toCzsjCrMoKcimeEAGxQMyGJKbQfGATIYMyGBAZipm+ktApK85XnPpSC+WnprMjAmDmTFhMFV1+/jj0q28t24n5TUNzP9oJ/XNB6/YlRlKjv4CiPwSuGbiEM4YNiBO1YtILKmFH2Duzu7GFrbsamTLrkYqahvZsquBiujrjTvraWhp45Ypw/nGpaPJ1g1gkV5LLXzpkpmRmxkiNzPE+CH9/2r/3n2t3PPqGh6dv5HXVm7nP64ez4VjBh6X2tydsKMbzSIxpBa+dGvRpl18Z/Yy1u7Yy2dOO4F/u3zcMZnEzd1Zvb2Ol5dv46Vl26iobeSC0UXMmDCYC8cU9cohpo3NbdQ2NjO4v559kPjSTVuJmebWMA/M/YhfvrmOjFAy35sxls9OKj7qG7zuztode3lp2VZeXL6N9VX1JBlMGZHPsLws3ijbQVXdPtJTk7hwTBEzTj2BC8YUkhmKb/i3tIX5/cJyfv6nD6mq28f5owq54/yTmDIiXze9JS4U+BJz6yrr+M7s5SzcuItzT87nx1efyon5WYf9Ph/uqOPFZdt4afk21lXuJcng7JJ8ZkwYzPTxgyjIjvwF0RZ2Fm6s4aVl23hlxXZ27t1HRmoyF44t4vJTBzNtdBEZoeO3Qpi788qK7dz96ho27KznzOEDmHJSPr9bUM7OvfsYP6Qff3/+CC4bP4iUZM1cIsePAl+OiXDY+d2CzfzkldW0hsN8/VOj+PzUElKSk3B36va1sruhhd2NLexpbGFPU+T17sYWqvc289aaStbu2IsZnF2Sx4xTB3Pp+EEU5aR3+bltYWfBhhpeWr6VV5Zvp7q+mcxQMheNHchXLjyZkcf4+YL5H1XzkzmrWVpey8iibP5l+hguGluEmdHU0sZzH1Qwa9561u+sp3hABv9vagnXnTk07n+NSDAo8OWY2r67iTufX8Hrq3aQnxWizZ09jS2Eu/hPKiXJmHjiAC6fMJjppwyiqF/XId+Z1rYwCzbU8GK0vz8cdu6/aRJTRxYc4dl0btXWPfzs1dW8vaaKwf3T+frFo7h2YnGHN5TDYeeNsh3877z1LNq0i9zMVG6eMpxbppxIfvZf3/fYP1Lq0AXv6/e10T8jldzM6FdGiP6ZqeRmpJKbGaJ/RqpuaMtBFPhyzLk7r67czmsrd5CVlkL/jNQDX/3ave6fGfmeFUqOeR/31tpGPvfIQtZV7uXHV5/KdWcOjcn7ltc08D+vr+XZJRX0S0/lSxeM4OYpw3u8yPyiTTX879z1vF62g1ByEtdOKqYgK8TW3U1s393E1t2NbKttorHl4GchkpOMzFAydU2tXb5/v/QUBmSFmDaqkFvOGc5JhdlHfK7S9ynwJTDqmlr44uOL+fOHO/nHC0/mny4edcS/WHY3tvCLP33IY/M3YQa3nVvCP3xyBP0zU4/o/T6q2suDf17PM4sqaAmHKcpJY3D/yAL3g/pFvg/un8Hg3HQG90+nMDuNlOQk2sKRv5hqG1uobWimtrGF3Q0t7GpopjbaZba1tpG31lTS0uZcMLqQ284t4byRBb3uxvHuhhZy0lNIitFfJeU1DfzyzXXkZqZy5vA8Jg8fQG5mKCbv3Vcp8CVQWtrC3PncCp5cWM6Vp5/Azz47gbSUnt/QbQs7fygt5+5X17CroZmZk4r5+sWjYjbksrG5jZRkIzXGN3Mr65p4/C+befz9Tezc28zJRdnces5wrpk4pFfcP1i0aRc3/PovjB2Uw4+uPrXDZz56Khx2Hn9/E//5ymrC7oTD0NwWWTJ79MAcziwZwJnD8zirJC9wQ2UV+BI47s79cz/iZ3PWcFZJHrP+blKPWn6lG2v4/gsrWVGxhzOHD+Cuz5xyVMEUD/ta23hx6TYefm8DKyr20C89hevPGsbNU06keEBmXGqqrGviM794h5SkJPa1hqmp38fNU4bzz5eMIif98P5iKq9p4FtPL2P++mrOG1nAT66dQH5WiCXltSzcUMOCjTUs3rTrwHQhQ/MyIuE/PI/zRxX22nUi3J2a+mY21TSwp7GFaaOLjuh9FPgSWH9cupVv/GEpxXkZPHLrWQzL7zjwtu9u4ievlPHckq0M6pfOdz49hitOO6HXdYkcjv2zpT787kbmrNyOu3PJuEF84fyTmHTi8ZsXqaUtzN/++n2WVdTy7BfP5YTcDO55dQ2/fX8Thdlp3Hn5OC6fMLjbf9ftW/VJZvzrjLFcf+bQDn+utS1M2bY6FmysYeGGGhZurKG6vpm0lCR+eu0ErjpjyLE63S61tIWp2NXI5poGNtU0UF7TwKbqejbXNLK5uv7AL6m8rBCL77z4iD5DgS+BtmBDDbf/ppRkM359y2QmtpsEbl9rGw/+eQO/emsdrWHn9vNO4osXjOgVXSCxVFHbyG/mb+KJBZvZ3djC584t4VvTR/f4xvPR+MELq3jo3Q3c+zenHxS0S8tr+dfnlrOiYg/njSzgB1eOp6Sg42c5OmrVDzmMlrq7s65yL997bgXvb6jh81NL+M5lY2L+jMT+0VabaxoOfJVHv2+qbmBrbeNBo9fSUpIYmpfJiXmZke/5mQyLfj+56MiGFyvwJfDWV+3ltkcWsn13E/f+zelMHz+IP5VV8sOXVrGpuoFLxg3kezPGdfoXQKJoaG7lp6+s5tH5mxg1MJt7/+YMxp3Q75h93vNLKvjqk0u49ZzhfP+KU/5qf1vY+c38jdzz2lqa28J8cdoI7vjkiAO/iA6nVd8TLW1hfvRSGY+8t5FzRuTzyxsnkpd15Dd5F23axWurtkdb6pFgP3RUVUF2iKF50SA/EOxZDMvLpCgnLWY3sPdT4IsA1Xv38YXHSvmgvJYJQ/qzdMtuTi7K5q7PjOO8kYXxLu+4entNJd98ehm1Dc388yWj+cJ5J8V8PH/Ztj1cfd+7TBiSy+NfOLvLm9Q79jTxwxdX8eKybZQUZPGDK09heH7WUbXqu/JUaTn/+twKCrPTmHXzJE454fDu06yrrOOnc9bw+qrIUNvivAyGRUP9wFd+JkMHZB73uZ8U+CJRTS1tfOOppcxdW8XXPjWKm6ecGPPRMn1FTX0z3529nDkrt3NWSR7/fd1pMbupu7uhhSt+9Q6NzW28+JWp3T49vd+fP6zizudWsLG6gVByEqGUpKNu1XdmaXktd/x2EbsamvnptRO48vTu+/V37Gni3jfW8vuF5WSGUrjjkyfxuaklvaoLUIEvcojWtrDmuCHS5/z0oi38+wurMOAHV53CVacPOapwDYedzz+6kHfW7eTJ2z/BpBPzDuvnm1ramDVvPR9W7uXbl42JWau+I1V1+/jS44tZsLGGL5xXwr9M77hff09TC7PmrufBd9bTFnZu+sSJfPmCkzt8ajreFPgi0qXymga+/vsllG7axYwJg/nRVeOP+AGme99Yy71vfMgPrzyFv5syPLaFHgMtbWH+48VVPDp/E1NPLuAXN5zBgGi//r7WNh7/y2Z+8eaH7Gpo4YrTTuAbl4zu1fd6FPgi0q22sPPA3I/4n9fXUpCdxj0zTzvsOYneXL2Dzz1SyrUTi7ln5oQ+Naz1D6XlfO/ZFQzsn8YDN01iXeVe7nltDeU1jZx7cj7fnj6WU4t7/zMZCnwR6bEVFbv56pMf8FFVPWeX5HHR2CIuHDOQEYVZXQb4xp31XPHLdxial8kz/3DOcRnyGWtLymu54zeL2L6nCYCxg/vxncvG9MppKjqjwBeRw9LYHOlHf2XFNlZvrwPgxPxMLhxTxEVjBnJWSR6hlI/7uhuaW7nmvvfYvqeJF748laF5vbfLozuVdU3816tr+cSIPK48bUjMh00eazEJfDN7CLgcqHT38Z0cMw24F0gFdrr7J6PbpwM/B5KBB939Jz0pXIEvEn8VtY28ubqSN8t28O5H1TS3hslOS+G8kQVcOKaIaaOL+OGLq3hh2VYeve0szh8VrCGuvU2sAv98YC/wWEeBb2a5wHvAdHffbGZF7l5pZsnAWuBiYAuwELjB3Vd1V7gCX6R3aWhu5d111by5egd/Kquksm7fgX3fvHQ0X7rg5DhWJ9CzwO92EKm7zzOz4V0cciMw2903R4+vjG4/C1jn7uujxTwJXAl0G/gi0rtkhlK4eNxALh43EHdn5dY9vFG2g7DDP3xyRLzLkx6KxVMDo4BUM3sbyAF+7u6PAUOA8nbHbQHO7uxNzOx24HaAYcOGxaAsETkWzIzxQ/r3udlEJTaBnwJMAi4CMoD5ZvaXw30Td58FzIJIl04M6hIRkXZiEfhbgGp3rwfqzWwecFp0e/u15oqBihh8noiIHIFYPGP+PDDVzFLMLJNIt00ZkZu0I82sxMxCwPXAH2PweSIicgS6beGb2RPANKDAzLYAdxEZfom7P+DuZWY2B1gGhIkMv1wR/dkvA68SGZb5kLuvPCZnISIi3dKDVyIiCaAnwzI1baCISEAo8EVEAkKBLyISEL2yD9/MqoBNR/jjBcDOGJYTb4l2PpB455Ro5wOJd06Jdj7w1+d0ort3OaFRrwz8o2Fmpd3duOhLEu18IPHOKdHOBxLvnBLtfODIzkldOiIiAaHAFxEJiEQM/FnxLiDGEu18IPHOKdHOBxLvnBLtfOAIzinh+vBFRKRjidjCFxGRDijwRUQCImEC38ymm9kaM1tnZt+Odz2xYGYbzWy5mS0xsz45uZCZPWRmlWa2ot22PDN73cw+jH4fEM8aD0cn5/N9M6uIXqclZvbpeNZ4OMxsqJm9ZWarzEhqQN0AAALcSURBVGylmX01ur0vX6POzqlPXiczSzezBWa2NHo+/x7dXmJm70cz7/fRWYm7fq9E6MM/mvVzezMz2whMdvc++8BIR2sim9nPgBp3/0n0l/MAd/+XeNbZU52cz/eBve5+TzxrOxJmNhgY7O6LzSwHWARcBdxK371GnZ3TdfTB62RmBmS5+14zSwXeAb4K/BOR5WWfNLMHgKXufn9X75UoLfwD6+e6ezOwf/1ciTN3nwfUHLL5SuDR6OtHifzP2Cd0cj59lrtvc/fF0dd1RNayGELfvkadnVOf5BF7o/+YGv1y4ELg6ej2Hl2jRAn8jtbP7bMXuB0HXjOzRdE1fxPFQHffFn29HRgYz2Ji5Mtmtiza5dNnuj/aM7PhwBnA+yTINTrknKCPXiczSzazJUAl8DrwEVDr7q3RQ3qUeYkS+IlqqrtPBC4DvhTtTkgoHulT7Ov9ivcDI4DTgW3Af8W3nMNnZtnAM8DX3H1P+3199Rp1cE599jq5e5u7n05kqdizgDFH8j6JEvgVJOD6ue5eEf1eCTxL5EIngh3Rftb9/a2Vca7nqLj7juj/kGHg1/Sx6xTtF34GeNzdZ0c39+lr1NE59fXrBODutcBbwBQg18z2r1rYo8xLlMBPuPVzzSwresMJM8sCLgFWdP1TfcYfgVuir28hsi5yn7U/GKOupg9dp+gNwf8Dytz9v9vt6rPXqLNz6qvXycwKzSw3+jqDyOCUMiLB/9noYT26RgkxSgcgOsTqXj5eP/dHcS7pqJjZSURa9RBZe/h3ffGc2q+JDOwgsibyc8AfgGFEpsG+zt37xI3QTs5nGpFuAgc2An/frv+7VzOzqcCfgeVE1qQG+C6RPu++eo06O6cb6IPXycwmELkpm0ykkf4Hd/9BNCOeBPKAD4Cb3H1fl++VKIEvIiJdS5QuHRER6YYCX0QkIBT4IiIBocAXEQkIBb6ISEAo8EVEAkKBLyISEP8fy2LL1FfVWFMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Class: 6    Predicted Class: 0\n"
     ]
    }
   ],
   "source": [
    "img, label = next(iter(test_loader))\n",
    "\n",
    "flat_img = img[0].view(1,784)\n",
    "with torch.no_grad():\n",
    "    pred = list(model(flat_img).numpy()[0])\n",
    "    print(f\"Actual Class: {label[0].item()}    Predicted Class: {pred.index(max(pred))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct/Total: 8491/10000\n",
      "Accuracy: 0.8491\n"
     ]
    }
   ],
   "source": [
    "correct_count = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, label in test_loader:\n",
    "        flat_data = data.view(data.shape[0], -1)\n",
    "        output = model(flat_data)\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct_count += pred.eq(label.view_as(pred)).sum().item()\n",
    "        \n",
    "print(f\"Correct/Total: {correct_count}/{len(test_loader.dataset)}\")\n",
    "print(f\"Accuracy: {correct_count/len(test_loader.dataset):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Untrained Model\n",
    "\n",
    "Lets take a look at how the model does if we dont train it. Lets create a new model and run it on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, label in test_loader:\n",
    "        flat_data = data.view(data.shape[0], -1)\n",
    "        output = model(flat_data)\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct_count += pred.eq(label.view_as(pred)).sum().item()\n",
    "        \n",
    "print(f\"Correct/Total: {correct_count}/{len(test_loader.dataset)}\")\n",
    "print(f\"Accuracy: {correct_count/len(test_loader.dataset):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
